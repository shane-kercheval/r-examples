---
title: "Regression and Other Stories"
author: "Shane Kercheval"
output:
  md_document:
    variant: markdown_github
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
#devtools::install_github('shane-kercheval/rtools')
#library(rtools)
# library(stringr)
# library(ggrepel)
# library(forecast)
#library(scales)
#library(lubridate)

library(knitr)

calculate_plot_width <- function(plot_height) { plot_height * 1.61803398875 }
plot_width_height_5 <- calculate_plot_width(5)
plot_width_height_6 <- calculate_plot_width(6)
plot_width_height_7 <- calculate_plot_width(7)
plot_width_height_8 <- calculate_plot_width(8)
```

```{r downloading_data, eval=FALSE, include=FALSE}
download.file(url='https://raw.githubusercontent.com/avehtari/ROS-Examples/master/ElectionsEconomy/data/hibbs.dat',
              destfile = 'data/hibbs.dat', quiet = TRUE)
```


# Overview

This document includes examples and exercises from `Regression and Other Stories` by Andrew Gelman, Jennifer Hill and Aki Vehtari, 2020, first edition.

# Resources

[Errata](https://avehtari.github.io/ROS-Examples/errata.html)

[Authors' Code](https://avehtari.github.io/ROS-Examples/examples.html#Examples_by_chapters)

# Packages

## statistical packages

```{r message=FALSE, warning=FALSE}
library(rstan)
library(rstanarm)
library(bayesplot)
library(loo)
```

## base packages

```{r message=FALSE, warning=FALSE}
library(broom)
library(broom.mixed)

library(tidyverse)
library(ggplot2)
library(scales)
```

## Settings

```{r}
theme_set(theme_light())
options(scipen=999) # non-scientific notation
options(dplyr.summarise.inform=F)
```

# Chapter 1 - Overview

## Simple Example with `stan_glm`

Load in the data:

```{r}
hibbs <- read.table('data/hibbs.dat', header = TRUE)
head(hibbs)
```

---

Graph data:

```{r figure.1.1.a, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
hibbs %>%
    ggplot(aes(x=growth, y=vote)) +
    geom_hline(yintercept = 50, color="red", linetype="dashed") +
    geom_text(aes(label=year)) +
    geom_smooth(method='lm') +
    scale_x_continuous(labels=function(.x)paste0(.x, '%')) +
    scale_y_continuous(labels=function(.x)paste0(.x, '%')) +
    labs(title="Forecasting the election from the economy",
         y="Incuming party's vote share",
         x="Average recent growth in personal",
         caption='Figure 1.1')
```

---

Build Model:

```{r}
model <- stan_glm(vote ~ growth, data=hibbs)
```

---

Model Summary:

```{r}
summary(model)
```

---

Print()

```{r}
print(model)
```

---

Model Coefficients:

```{r}
coef(model)
```

---

Compare to `lm()`:

```{r}
summary(lm(vote ~ growth, data=hibbs))
```

(pretty close)

---

Graph using model coefficients rather than `geom_smooth(method='lm')`

```{r figure.1.1.a2, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
hibbs %>%
    ggplot(aes(x=growth, y=vote)) +
    geom_hline(yintercept = 50, color="red", linetype="dashed") +
    geom_text(aes(label=year)) +
    #geom_smooth(method='lm') +
    geom_abline(intercept = coef(model)['(Intercept)'], slope = coef(model)['growth']) +
    scale_x_continuous(labels=function(.x)paste0(.x, '%')) +
    scale_y_continuous(labels=function(.x)paste0(.x, '%')) +
    labs(title="Forecasting the election from the economy",
         y="Incuming party's vote share",
         x="Average recent growth in personal",
         caption='Figure 1.1')
```

---

# Chapter 3 - Basic Methods

## Log-Log Interpretation

Example from `Regression & Other Stories pg 39. (Data found elsewhere.)

### Example Model

```{r message=FALSE, warning=FALSE}
metabolic_rate <- read_csv("data/Primate Body Mass and Basal Metabolic Rate.csv")
head(metabolic_rate)
```

```{r chapter_3_log_log_not_scaled, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
metabolic_rate %>%
    ggplot(aes(x=`Primate Mass`, y=`Metabolic Rate`)) +
    geom_point() +
    geom_text(data=metabolic_rate, 
              aes(x=`Primate Mass`, y=`Metabolic Rate`,
                  label=glue::glue("({ `Primate Mass` }, { `Metabolic Rate` })"),
                  color=NULL),
              vjust=-0.5, check_overlap = TRUE) +
    labs(title="Primate Body Mass And Basal Metabolic Rate",
         subtitle = "(Not Scaled)")
```

```{r chapter_3_log_log_scaled, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
metabolic_rate %>%
    ggplot(aes(x=`Primate Mass`, y=`Metabolic Rate`)) +
    geom_point() +
    geom_text(data=metabolic_rate, 
              aes(x=`Primate Mass`, y=`Metabolic Rate`,
                  label=glue::glue("({ `Primate Mass` }, { `Metabolic Rate` })"),
                  color=NULL),
              vjust=-0.5, check_overlap = TRUE) +
    scale_x_log10() +
    scale_y_log10() +
    labs(title="Primate Body Mass And Basal Metabolic Rate",
         subtitle = "Log Scaled")
```

```{r}
model <- lm(log(`Metabolic Rate`) ~ log(`Primate Mass`), data=metabolic_rate)
summary(model)
```

```{r}
coef(model)
```

### Interpretation

#### Interpretation from `Regression and Other Stores`

From `pg. 40`

"For example, when increasing body mass on this curve by a factor of 2, metabolic rate is multiplied by `2^0.74` = `1.7`. Multiplgying body mass by `10` corresponds to multiplying metabolic rate by `10^0.74` = `5.5`, and so forth."

```{r}
(primate_mass_coefficient <- unname(coef(model)['log(`Primate Mass`)']))
```

Lets test this. We'll start with a body mass of `105`.

```{r}
(log_prediction_105 <- predict(model, newdata = data.frame(`Primate Mass`=105, check.names = FALSE)))
(prediction_105 <- exp(log_prediction_105))
```

Our prediction of the metabolic rate is ``r prediction_105``.

What is our prediction if we **double** the body mass?

We would expect a Metabolic Rate of ``r 2^primate_mass_coefficient * prediction_105``.

```{r}
2^primate_mass_coefficient * prediction_105
```

What is the actual prediction if we double the body mass?

```{r}
log_prediction_210 <- predict(model, newdata = data.frame(`Primate Mass`=210, check.names = FALSE))
(prediction_210 <- exp(log_prediction_210))
```

---

What is our prediction if we multiply body mass by `10`?

We would expect a Metabolic Rate of ``r 10^primate_mass_coefficient * prediction_105``.

```{r}
10^primate_mass_coefficient * prediction_105
```

What is the actual prediction if we double the body mass?

```{r}
log_prediction_1050 <- predict(model, newdata = data.frame(`Primate Mass`=1050, check.names = FALSE))
(prediction_1050 <- exp(log_prediction_1050))
```

---- 

#### Interpretation from `Introductory Econometrics 7e`

> "A one-unit difference in `log x` corresponds to an additive difference of `b` in `log y`. (R&OS pg. 39)

This is essentially "elasticity" and is interpreted as a `1%` change in x has a `b`% change in `y` (Intro Econometrics pg. 39), although this does not hold for large changes in `y` (Intro Econometrics pg. 186).

```{r}
format_percent <- function(.x) { paste0(round(.x, 3), '%')}
format_percent_scale <- function(.x) { paste0(round(.x * 100, 3), '%')}

(expected_one_percent_change <- format_percent(primate_mass_coefficient))
```

So, the interpretation of the `log(Primate Mass)` coefficient is that a `1%` change in `Primate Mass` results in a `~`r expected_one_percent_change`` change in `Metabolic Rate`.


Let's see if this is true.

If the `Primate Mass` is `105` then our prediction of `log(Metabolic Rate`) is ``r log_prediction_105``, which means our prediction of `Metabolic Rate` is ``r prediction_105``, which matches the point on the graph.

Now let's change `Primate Mass` (x) by `1%` and see how much `Metabolic Rate` (y) changes by.

```{r}
(one_percent_change <- (0.01 * 105) + 105)
one_percent_change_prediction <- predict(model, newdata = data.frame(`Primate Mass`=one_percent_change, check.names = FALSE))
(one_percent_change_prediction <- exp(one_percent_change_prediction))
```

So if `Primate Mass` is ``r one_percent_change`` then we predict that `Metabolic Rate` is ``r one_percent_change_prediction``.

So a `1%` change in `Primate Mass` resulted in the following percent change for `Metabolic Rate`:

```{r}
format_percent_scale((one_percent_change_prediction - prediction_105) / prediction_105)
```

Which matches the expected percent change from the coefficient.

```{r}
primate_mass_coefficient
```

---

Now, lets try with a larger change.

Lets predict `Metabolic Change` for a `Primate Mass` of `9,500`

```{r}
(percent_change <- (9500 - 105) / 105)
```

The percent-change in `Primate Mass` between these two values is ``r format_percent_scale(percent_change)``.

```{r}
(expected_percent_change_y <- as.numeric(coef(model)["log(`Primate Mass`)"]) * percent_change)
```

Therefore, if `Primate Mass` changes by ``r format_percent_scale(percent_change)``, the **expected** percent change in `Metabolic Rate` should be ``r format_percent_scale(expected_percent_change_y)``.

But the actual percent change is:

```{r}
(prediction_9500 <- exp(predict(model, newdata = data.frame(`Primate Mass`=9500, check.names = FALSE))))
format_percent_scale((prediction_9500 - prediction_105) / prediction_105)
```

Which is quite lower than what we expected.

So this rule of thumb doesn't work across large changes in `y`.

### Predictions

According to `Introductory Econometrics, Wooldridge (pg. 206)`,

> Because the exponential undoes the log, our first guess for predicting y (when dependent variable is log(y)) is to simply exponentiate the predicted value for `log(y): y_predicted = exp(log y_predicted))`. **This does not work; in fact, it will systematically underestimate the expected value of y**.

One adjustment that the author describes is the `Duan smearing estimate`.

> Given an esimtate `a0`, we can predict `y` as 
>
> `y_predicted = a0 * exp(log y_predicted)`

where, 

> `a0 = sum(exp(residuals)) / N`

The code below implements the `Duan smearing estimate`.

Note, that this adjustment necessary, not just for `log y = log x` models, but for `log y = x` models (any time the dependent variable is log y, regardless of X).

```{r}
#' This method returns the adjustment coefficient described in `Introductory Econometrics, Wooldridge (pg. 206)`
#' @param .model the regression model
duan_smearing_adjustment <- function(.model) {
    model_residuals <- residuals(.model)
    duan_smearing_coefficient <- sum(exp(model_residuals)) / length(model_residuals)
    
    return (duan_smearing_coefficient)
}

#' This method returns the prediction of `y`, when the dependent variable is `log y`, based on the adjustment coefficient described in `Introductory Econometrics, Wooldridge (pg. 206)`
#' @param .model the regression model
#' @param .newdata the data (e.g. test data) from which predictions will be generated
predict_from_log_y <- function(.model, .newdata) {
    
    duan_smearing_coefficient <- duan_smearing_adjustment(.model)
    .predictions <- predict(.model, newdata=.newdata)
    .predictions <- duan_smearing_coefficient*exp(.predictions)

    return (.predictions)
}
```

Now, let's create predictions for all `Primate Masses` between `50` and `80000`, which is around the interval of our data.

```{r}
all_predictions <- data.frame(`Primate Mass`=seq(50, 80000), check.names = FALSE)
log_y_predictions <- predict(model, newdata=all_predictions)

# this simple adjustment is also described on pg 206 but assumes normal residuals
all_predictions$`Predictions - Unadjusted` <- exp(log_y_predictions)
all_predictions$`Predictions - Adjusted - Simple` <- exp(((summary(model)$sigma)^2)/2)*exp(log_y_predictions)
all_predictions$`Predictions - Adjusted - Duan` <- predict_from_log_y(.model=model, .newdata=all_predictions)
head(all_predictions)
```

```{r chapter_3_log_log_scaled_regression, fig.height=5, fig.width=plot_width_height_5, message=FALSE, warning=FALSE}
predictions_long <- all_predictions %>% 
    # get the original values, where applicable
    #left_join(metabolic_rate, by = 'Primate Mass') %>%
    pivot_longer(-`Primate Mass`, names_to = 'Prediction Type', values_to='Metabolic Rate')

metabolic_rate_plot <- predictions_long %>%
    ggplot(aes(x=`Primate Mass`, y=`Metabolic Rate`, color=`Prediction Type`)) +
    geom_point(data=metabolic_rate, aes(x=`Primate Mass`, y=`Metabolic Rate`, color=NULL)) +
    geom_text(data=metabolic_rate, 
              aes(x=`Primate Mass`, y=`Metabolic Rate`,
                  label=glue::glue("({ `Primate Mass` }, { `Metabolic Rate` })"),
                  color=NULL),
              vjust=-0.5, check_overlap = TRUE) +
    geom_line()

metabolic_rate_plot +
    scale_x_log10() +
    scale_y_log10() +
    labs(title="Primate Body Mass And Basal Metabolic Rate",
         subtitle = "Log Scaled")
```

```{r chapter_3_log_log_unscaled_regression, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
metabolic_rate_plot +
    labs(title="Primate Body Mass And Basal Metabolic Rate",
         subtitle = "Unscaled")
```

---

### Simulation of Log-Log Predictions

See discussion in previous section regarding systematic underprediction of `y` when dependent varaible is `log y`.

`log y = a + b*log x + random-noise`

```{r}
set.seed(1)
intercept <- 4
b_coefficient <- 3
simulated_x <- rexp(100000, rate = 0.5) + 1
noise <- rnorm(100000, sd = 0.5)

simulated_y <- exp(intercept + b_coefficient*log(simulated_x) + noise)

simulated_data <- data.frame(simulated_x, simulated_y)
simulated_data %>%
    ggplot(aes(x=simulated_x, y=simulated_y)) +
    geom_point(alpha=0.1) +
    scale_x_log10(breaks=2^seq(0,6)) +
    scale_y_log10(breaks=10^seq(1,6)) +
    labs(title="Simulated Data (`log y = a + b*log x + random-noise`)",
         subtitle = "Graphed on a log-scale.")
```

---

Create training/test sets, fit model on training data.

```{r}
training_indices <- sample.int(n=nrow(simulated_data), size = 0.7*nrow(simulated_data), replace = FALSE)
training_data <- simulated_data[training_indices,]
test_data <- simulated_data[-training_indices,]
model <- lm(log(simulated_y) ~ log(simulated_x), data=training_data)
summary(model)
```

---

Predict on test data.

```{r}
log_y_predictions <- predict(model, newdata=test_data)

# this simple adjustment is also described on pg 206 but assumes normal residuals
test_data$`Predictions - Unadjusted` <- exp(log_y_predictions)
test_data$`Predictions - Adjusted - Simple` <- exp(((summary(model)$sigma)^2)/2)*exp(log_y_predictions)
test_data$`Predictions - Adjusted - Duan` <- predict_from_log_y(.model=model, .newdata=test_data)
head(test_data)
```

---

```{r chapter_3_log_log_scaled_simulation, fig.height=5, fig.width=plot_width_height_5, message=FALSE, warning=FALSE}
predictions_long <- test_data %>%
    select(-simulated_y) %>%
    # get the original values, where applicable
    #left_join(metabolic_rate, by = 'Primate Mass') %>%
    pivot_longer(-simulated_x, names_to = 'Prediction Type', values_to='Predicted Y')

simulated_plot <- predictions_long %>%
    ggplot(aes(x=simulated_x, y=`Predicted Y`, color=`Prediction Type`)) +
    geom_point(data=test_data, aes(x=simulated_x, y=simulated_y, color=NULL), alpha=0.2) +
    geom_line()

simulated_plot +
    scale_x_log10(breaks=2^seq(0,6)) +
    scale_y_log10(breaks=10^seq(1,6)) +
    labs(title="Simulated Data & Predictions",
         subtitle = "Log Scaled",
         caption="The 'Simple' and 'Duan' adjustments are slow close that they overlap,\nand the Duan is being hidden behind the Simple.")
```

---

```{r chapter_3_log_log_unscaled_simulation, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
simulated_plot +
    labs(title="Simulated Data & Predictions",
         subtitle = "Not Scaled",
         caption="The 'Simple' and 'Duan' adjustments are slow close that they overlap,\nand the Duan is being hidden behind the Simple.")
```

---

The adjustments seem to make sense, visualy; but we can check the `Root Mean Square Error` (`RMSE`) to see if the adjustments actually results in a better **out-of-sample** fit, below (which it appears is the case; there is a lower error for the adjusted predictions).

```{r}
rmse = function(fitted, actual){
  sqrt(mean((fitted - actual)^2))
}

rmse(fitted=test_data$`Predictions - Unadjusted`, actual=test_data$simulated_y)
rmse(fitted=test_data$`Predictions - Adjusted - Simple`, actual=test_data$simulated_y)
rmse(fitted=test_data$`Predictions - Adjusted - Duan`, actual=test_data$simulated_y)
```

NOTE: the "Simple" adjustment (found in `Introductory Econometrics, Wooldridge (pg. 206)`) is only valid for residuals that are normally distributed. In this simulation, the residuals are normally distributed; and the Simple and Duan adjustments are quite similar.

---

We can do another performance check using `R-Squared`, which is a measure of the percent of variance in the dependent variable (y) that is explained by the model. The higher the R-squared, the better.

```{r}
#' these functions are from `Business Data Science, Taddy, pg 72`
#' @param y the actual y values
#' @param pred the predictions; must be probabilities (0<pred<1) for binomial
deviance <- function(y, pred, family=c("gaussian","binomial")){
    family <- match.arg(family)
    if(family=="gaussian"){
        return( sum( (y-pred)^2 ) )
    }else{
        if(is.factor(y)) y <- as.numeric(y)>1
        return( -2*sum( y*log(pred) + (1-y)*log(1-pred) ) )
    }
}
#' these functions are from `Business Data Science, Taddy, pg 72`
#' returns r-squared which is a measure of the percent of variance in the dependent variable (y) that is explained by the model.
#' @param y the actual y values
#' @param pred the predictions; must be probabilities (0<pred<1) for binomial
R2 <- function(y, pred, family=c("gaussian","binomial")){
    fam <- match.arg(family)
    if(fam=="binomial"){
        if(is.factor(y)){ y <- as.numeric(y)>1 }
    }
    dev <- deviance(y, pred, family=fam)
    dev0 <- deviance(y, mean(y), family=fam)
    return(1-dev/dev0)
}
```

We can see that the adjusted predictions do have a higher `R-Squared` than the unadjsuted.

```{r}
R2(pred=test_data$`Predictions - Unadjusted`, y=test_data$simulated_y)
R2(pred=test_data$`Predictions - Adjusted - Simple`, y=test_data$simulated_y)
R2(pred=test_data$`Predictions - Adjusted - Duan`, y=test_data$simulated_y)
```

# Chapter 4 - Statistcal Inference

## Confidence Interval of Proportion

```{r}
sample_size <- 1000
respond_yes <- 700

(estimate <- respond_yes / sample_size)
(standard_error <- sqrt(estimate * (1 - estimate) / sample_size))
(z_scores <- qnorm(c(0.025, 0.975)))
(confidence_interval_95 <- estimate + (z_scores * standard_error))
```

---

Compare to R's `prop.test`.

```{r}
prop.test(x=respond_yes, n=sample_size)
```

# Chapter 5 - Simulation

## How many girls in 400 births?

```{r}
probability_girl <- 0.488
sample_size <- 400
# one random sample (simulated)
number_of_simulated_samples <- 1
set.seed(1)
rbinom(n = number_of_simulated_samples, size=sample_size, prob = probability_girl)
```

```{r}
number_of_simulated_samples <- 1000
set.seed(1)
simulations <- rbinom(n = number_of_simulated_samples, size=sample_size, prob = probability_girl)
simulations[1:10]
```

95% Interval

```{r}
quantile(simulations, c(0.025, 0.975))
```

```{r simulations_girls, fig.height=5, fig.width=plot_width_height_5}
hist(simulations)
```

---

Accounting for twins.

First, simulate birth types of 400 births.

```{r}
set.seed(2)
probability_girl_if_twins <- 0.495
probability_of_twins_fraternal <- 1/125  # each has a 49.5% of being a girl
probability_of_twins_identical <- 1/300  # 49.5% chance of being a pair of girls.

simulate_birth_types <- function() {
    
    sample(x=c('fraternal twin', 'identical twin', 'single born'),
           size = sample_size,
           replace = TRUE,
           prob = c(probability_of_twins_fraternal,
                    probability_of_twins_identical,
                    1 - probability_of_twins_fraternal - probability_of_twins_identical))
}
birth_type <- simulate_birth_types()
table(birth_type)
```

Simulating Number of Girls if Fraternal Twin. In this scenario, there are `2` different people, each of which has a ``r format_percent_scale(probability_girl_if_twins)` percent chance of being a girl. So the possible outcomes are `0`, `1`, `2`

- `0`: 0 girls (both boys)
- `1`: 1 girl
- `2`: 2 both

```{r simulations_fraternal_twins, fig.height=5, fig.width=plot_width_height_5}
hist(rbinom(n=10000,  # simulate this scenario 10K times
            size=2, # two different possible chances of being a girl
            prob=probability_girl_if_twins))
```

Simulating Number of Girls if Identical Twin. In this scenario, they are either both boys, or both girls. So the possible outcomes are either `0` or `2`

- `0`: 0 girls (both boys)
- `2`: both girls

In other words, we'll simulate the binary outcome of either both girls or both boys, but the former means we have to count 2 people, so we'll multiple the number of people by 2

```{r simulations_identical_twins, fig.height=5, fig.width=plot_width_height_5}
hist(2 * rbinom(n=10000,  # simulate this scenario 10K times
                size=1, # two different possible chances of being a girl
                prob=probability_girl_if_twins))
```

Now, we will do 1000 simulations of births, considering fraternal/identical twins; each simulation has a sample-size of 400.

```{r}
set.seed(1)
simulation_results <- replicate(1000, {
    birth_type <- simulate_birth_types()
    
    sample_of_girls <- map_dbl(birth_type, ~ {

        if(. == 'fraternal twin') {
            # simulate number of girls for this particular simulated birth_type
            number_of_girls <- rbinom(n=1,
                   size=2, # two different possible chances of being a girl
                   prob=probability_girl_if_twins)
            
        } else if(. == 'identical twin') {
            # simulate number of girls for this particular simulated birth_type
            number_of_girls <- 2 * rbinom(n=1,
                size=1, # two different possible chances of being a girl
                prob=probability_girl_if_twins)
            
        } else if(. == 'single born') {
            # simulate number of girls for this particular simulated birth_type
            number_of_girls <- rbinom(1, 1, probability_girl)
            
        } else {
            stop()
        }
        
        return(number_of_girls)
    })
    stopifnot(length(sample_of_girls) == sample_size)
    return (sum(sample_of_girls))
})
```

```{r}
quantile(simulation_results, c(0.025, 0.975))
```

```{r simulations_twins, fig.height=5, fig.width=plot_width_height_5}
hist(simulation_results)
```

## Simulation of continuous and mixed discrete/continuous models

```{r}
n_sims <- 1000
y1 <- rnorm(n = n_sims, mean = 3, sd = 0.5)
y2 <- exp(x = y1)
y3 <- rbinom(n = n_sims, size = 20, prob = 0.6)
y4 <- rpois(n = n_sims, lambda = 5)
```

```{r simulations_continuous, echo=FALSE, fig.height=6, fig.width=plot_width_height_6}
par(mar=c(4,3,4,3),  mgp=c(1.5,.5,0), tck=-.01)
par(mfrow=c(2,2))
hist(y1, breaks=seq(floor(min(y1)), ceiling(max(y1)), 0.2), main="1000 draws from normal dist with dist. with mean 3, sd 0.5")
hist(y2, breaks=seq(0, ceiling(max(y2)) + 5, 5),  main="1000 draws from corresponding lognormal dist.")
hist(y3, breaks=seq(-0.5, 20.5, 1), main="1000 draws from binomial dist. with 20 tries, probability 0.6")
hist(y4, breaks=seq(-0.5, max(y4) + 1, 1), main="1000 draws from Poisson dist. with mean 5")
```

## Median Absolute Deviation (`MAD SD`)

```{r simulations_mad_sd, fig.height=6, fig.width=plot_width_height_6}
set.seed(1)
z <- rnorm(10000, 5, 2)
hist(z)
```

```{r}
rnd3 <- function(.x) {
    round(.x, 3)
}
glue::glue("mean = { rnd3(mean(z)) }, sd = { rnd3(sd(z)) }, median = { rnd3(median(z)) }, mad sd = { rnd3(mad(z)) }")
```

```{r}
constant <- 1.4826  # 1.483 defined R&OS pg 73; but function uses more specific number
constant * median(abs(z - median(z)))
mad(z)
```

---

The above is a single sample if `10,000` observations.

The `standard error` (i.e. expected **standard deviation** of the **distribution** of **sample means** (if we were going to run this simulation many times (or draw a random sample from the population many times))) is:

```{r}
sd(z) / sqrt(length(z))
```

We can also simulate this.

First, lets run a `1,000` simulations of drawing a sample of `10,000` observations. Each time we'll take the mean of those 10,000 observations. So we'll have a distribution of (1000) sample means.

The standard deviation of the distribution of sample means is:

```{r}
set.seed(1)
simulations <- replicate(1000, mean(rnorm(10000, 5, 2)))
sd(simulations)
```

Which is fairly close to our calculated standard error.

```{r}
quantile(simulations, c(0.025, 0.975))
```

```{r simulations_sample_means, fig.height=6, fig.width=plot_width_height_6}
hist(simulations, main = "Distribution of Sample Means")
```
