---
title: "Regression and Other Stories"
author: "Shane Kercheval"
output:
  md_document:
    variant: markdown_github
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
#devtools::install_github('shane-kercheval/rtools')
#library(rtools)
# library(stringr)
# library(ggrepel)
# library(forecast)
#library(scales)
#library(lubridate)

library(knitr)

calculate_plot_width <- function(plot_height) { plot_height * 1.61803398875 }
plot_width_height_5 <- calculate_plot_width(5)
plot_width_height_6 <- calculate_plot_width(6)
plot_width_height_7 <- calculate_plot_width(7)
plot_width_height_8 <- calculate_plot_width(8)
```

```{r downloading_data, eval=FALSE, include=FALSE}
download.file(url='https://raw.githubusercontent.com/avehtari/ROS-Examples/master/ElectionsEconomy/data/hibbs.dat',
              destfile = 'data/hibbs.dat', quiet = TRUE)
```

# Overview

This document includes examples and exercises from `Regression and Other Stories` by Andrew Gelman, Jennifer Hill and Aki Vehtari, 2020, first edition.

# Resources

[Errata](https://avehtari.github.io/ROS-Examples/errata.html)

[Authors' Code](https://avehtari.github.io/ROS-Examples/examples.html#Examples_by_chapters)

# Packages

## statistical packages

```{r message=FALSE, warning=FALSE}
library(rstan)
library(rstanarm)
library(bayesplot)
library(loo)
```

## base packages

```{r message=FALSE, warning=FALSE}
library(broom)
library(broom.mixed)

library(tidyverse)
library(ggplot2)
library(scales)
library(ggridges)
```

## Settings

```{r}
theme_set(theme_light())
options(scipen=999) # non-scientific notation
options(dplyr.summarise.inform=F)
```

```{r include=FALSE}
hibbs <- read.table('data/hibbs.dat', header = TRUE)
metabolic_rate <- read_csv("data/Primate Body Mass and Basal Metabolic Rate.csv")
```

# Chapter 1 - Overview

## Simple Example with `stan_glm`

Load in the data:

```{r}
head(hibbs)
```

---

Graph data:

```{r figure.1.1.a, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
hibbs %>%
    ggplot(aes(x=growth, y=vote)) +
    geom_hline(yintercept = 50, color="red", linetype="dashed") +
    geom_text(aes(label=year)) +
    geom_smooth(method='lm') +
    scale_x_continuous(labels=function(.x)paste0(.x, '%')) +
    scale_y_continuous(labels=function(.x)paste0(.x, '%')) +
    labs(title="Forecasting the election from the economy",
         y="Incuming party's vote share",
         x="Average recent growth in personal",
         caption='Figure 1.1')
```

---

Build Model:

```{r}
model <- stan_glm(vote ~ growth, data=hibbs)
```

---

Model Summary:

```{r}
summary(model)
```

---

Print()

```{r}
print(model)
```

---

Model Coefficients:

```{r}
coef(model)
```

---

Compare to `lm()`:

```{r}
summary(lm(vote ~ growth, data=hibbs))
```

(pretty close)

---

Graph using model coefficients rather than `geom_smooth(method='lm')`

```{r figure.1.1.a2, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
hibbs %>%
    ggplot(aes(x=growth, y=vote)) +
    geom_hline(yintercept = 50, color="red", linetype="dashed") +
    geom_text(aes(label=year)) +
    #geom_smooth(method='lm') +
    geom_abline(intercept = coef(model)['(Intercept)'], slope = coef(model)['growth']) +
    scale_x_continuous(labels=function(.x)paste0(.x, '%')) +
    scale_y_continuous(labels=function(.x)paste0(.x, '%')) +
    labs(title="Forecasting the election from the economy",
         y="Incuming party's vote share",
         x="Average recent growth in personal",
         caption='Figure 1.1')
```

```{r include=FALSE}
rm(model)
```

---

# Chapter 3 - Basic Methods

## Log-Log Interpretation

Example from `Regression & Other Stories pg 39. (Data found elsewhere.)

### Example Model

```{r message=FALSE, warning=FALSE}
head(metabolic_rate)
```

```{r chapter_3_log_log_not_scaled, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
metabolic_rate %>%
    ggplot(aes(x=`Primate Mass`, y=`Metabolic Rate`)) +
    geom_point() +
    geom_text(data=metabolic_rate, 
              aes(x=`Primate Mass`, y=`Metabolic Rate`,
                  label=glue::glue("({ `Primate Mass` }, { `Metabolic Rate` })"),
                  color=NULL),
              vjust=-0.5, check_overlap = TRUE) +
    labs(title="Primate Body Mass And Basal Metabolic Rate",
         subtitle = "(Not Scaled)")
```

```{r chapter_3_log_log_scaled, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
metabolic_rate %>%
    ggplot(aes(x=`Primate Mass`, y=`Metabolic Rate`)) +
    geom_point() +
    geom_text(data=metabolic_rate, 
              aes(x=`Primate Mass`, y=`Metabolic Rate`,
                  label=glue::glue("({ `Primate Mass` }, { `Metabolic Rate` })"),
                  color=NULL),
              vjust=-0.5, check_overlap = TRUE) +
    scale_x_log10() +
    scale_y_log10() +
    labs(title="Primate Body Mass And Basal Metabolic Rate",
         subtitle = "Log Scaled")
```

```{r}
model <- lm(log(`Metabolic Rate`) ~ log(`Primate Mass`), data=metabolic_rate)
summary(model)
```

```{r}
coef(model)
```

### Interpretation

#### Interpretation from `Regression and Other Stores`

From `pg. 40`

"For example, when increasing body mass on this curve by a factor of 2, metabolic rate is multiplied by `2^0.74` = `1.7`. Multiplgying body mass by `10` corresponds to multiplying metabolic rate by `10^0.74` = `5.5`, and so forth."

```{r}
(primate_mass_coefficient <- unname(coef(model)['log(`Primate Mass`)']))
```

Lets test this. We'll start with a body mass of `105`.

```{r}
(log_prediction_105 <- predict(model, newdata = data.frame(`Primate Mass`=105, check.names = FALSE)))
(prediction_105 <- exp(log_prediction_105))
```

Our prediction of the metabolic rate is ``r prediction_105``.

What is our prediction if we **double** the body mass?

We would expect a Metabolic Rate of ``r 2^primate_mass_coefficient * prediction_105``.

```{r}
2^primate_mass_coefficient * prediction_105
```

What is the actual prediction if we double the body mass?

```{r}
log_prediction_210 <- predict(model, newdata = data.frame(`Primate Mass`=210, check.names = FALSE))
(prediction_210 <- exp(log_prediction_210))
```

---

What is our prediction if we multiply body mass by `10`?

We would expect a Metabolic Rate of ``r 10^primate_mass_coefficient * prediction_105``.

```{r}
10^primate_mass_coefficient * prediction_105
```

What is the actual prediction if we double the body mass?

```{r}
log_prediction_1050 <- predict(model, newdata = data.frame(`Primate Mass`=1050, check.names = FALSE))
(prediction_1050 <- exp(log_prediction_1050))
```

---- 

#### Interpretation from `Introductory Econometrics 7e`

> "A one-unit difference in `log x` corresponds to an additive difference of `b` in `log y`. (R&OS pg. 39)

This is essentially "elasticity" and is interpreted as a `1%` change in x has a `b`% change in `y` (Intro Econometrics pg. 39), although this does not hold for large changes in `y` (Intro Econometrics pg. 186).

```{r}
format_percent <- function(.x) { paste0(round(.x, 3), '%')}
format_percent_scale <- function(.x) { paste0(round(.x * 100, 3), '%')}

(expected_one_percent_change <- format_percent(primate_mass_coefficient))
```

So, the interpretation of the `log(Primate Mass)` coefficient is that a `1%` change in `Primate Mass` results in a `~`r expected_one_percent_change`` change in `Metabolic Rate`.


Let's see if this is true.

If the `Primate Mass` is `105` then our prediction of `log(Metabolic Rate`) is ``r log_prediction_105``, which means our prediction of `Metabolic Rate` is ``r prediction_105``, which matches the point on the graph.

Now let's change `Primate Mass` (x) by `1%` and see how much `Metabolic Rate` (y) changes by.

```{r}
(one_percent_change <- (0.01 * 105) + 105)
one_percent_change_prediction <- predict(model, newdata = data.frame(`Primate Mass`=one_percent_change, check.names = FALSE))
(one_percent_change_prediction <- exp(one_percent_change_prediction))
```

So if `Primate Mass` is ``r one_percent_change`` then we predict that `Metabolic Rate` is ``r one_percent_change_prediction``.

So a `1%` change in `Primate Mass` resulted in the following percent change for `Metabolic Rate`:

```{r}
format_percent_scale((one_percent_change_prediction - prediction_105) / prediction_105)
```

Which matches the expected percent change from the coefficient.

```{r}
primate_mass_coefficient
```

---

Now, lets try with a larger change.

Lets predict `Metabolic Change` for a `Primate Mass` of `9,500`

```{r}
(percent_change <- (9500 - 105) / 105)
```

The percent-change in `Primate Mass` between these two values is ``r format_percent_scale(percent_change)``.

```{r}
(expected_percent_change_y <- as.numeric(coef(model)["log(`Primate Mass`)"]) * percent_change)
```

Therefore, if `Primate Mass` changes by ``r format_percent_scale(percent_change)``, the **expected** percent change in `Metabolic Rate` should be ``r format_percent_scale(expected_percent_change_y)``.

But the actual percent change is:

```{r}
(prediction_9500 <- exp(predict(model, newdata = data.frame(`Primate Mass`=9500, check.names = FALSE))))
format_percent_scale((prediction_9500 - prediction_105) / prediction_105)
```

Which is quite lower than what we expected.

So this rule of thumb doesn't work across large changes in `y`.

```{r include=FALSE}
rm(model)
rm(expected_one_percent_change)
rm(expected_percent_change_y)
rm(log_prediction_105)
rm(log_prediction_1050)
rm(log_prediction_210)
rm(one_percent_change)
rm(one_percent_change_prediction)
rm(percent_change)
rm(prediction_105)
rm(prediction_1050)
rm(prediction_210)
rm(prediction_9500)
rm(primate_mass_coefficient)
```

### Predictions

According to `Introductory Econometrics, Wooldridge (pg. 206)`,

> Because the exponential undoes the log, our first guess for predicting y (when dependent variable is log(y)) is to simply exponentiate the predicted value for `log(y): y_predicted = exp(log y_predicted))`. **This does not work; in fact, it will systematically underestimate the expected value of y**.

One adjustment that the author describes is the `Duan smearing estimate`.

> Given an esimtate `a0`, we can predict `y` as 
>
> `y_predicted = a0 * exp(log y_predicted)`

where, 

> `a0 = sum(exp(residuals)) / N`

The code below implements the `Duan smearing estimate`.

Note, that this adjustment necessary, not just for `log y = log x` models, but for `log y = x` models (any time the dependent variable is log y, regardless of X).

```{r}
#' This method returns the adjustment coefficient described in `Introductory Econometrics, Wooldridge (pg. 206)`
#' @param .model the regression model
duan_smearing_adjustment <- function(.model) {
    model_residuals <- residuals(.model)
    duan_smearing_coefficient <- sum(exp(model_residuals)) / length(model_residuals)
    
    return (duan_smearing_coefficient)
}

#' This method returns the prediction of `y`, when the dependent variable is `log y`, based on the adjustment coefficient described in `Introductory Econometrics, Wooldridge (pg. 206)`
#' @param .model the regression model
#' @param .newdata the data (e.g. test data) from which predictions will be generated
predict_from_log_y <- function(.model, .newdata) {
    
    duan_smearing_coefficient <- duan_smearing_adjustment(.model)
    .predictions <- predict(.model, newdata=.newdata)
    .predictions <- duan_smearing_coefficient*exp(.predictions)

    return (.predictions)
}
```

Now, let's create predictions for all `Primate Masses` between `50` and `80000`, which is around the interval of our data.

```{r}
model <- lm(log(`Metabolic Rate`) ~ log(`Primate Mass`), data=metabolic_rate)
all_predictions <- data.frame(`Primate Mass`=seq(50, 80000), check.names = FALSE)
log_y_predictions <- predict(model, newdata=all_predictions)

# this simple adjustment is also described on pg 206 but assumes normal residuals
all_predictions$`Predictions - Unadjusted` <- exp(log_y_predictions)
all_predictions$`Predictions - Adjusted - Simple` <- exp(((summary(model)$sigma)^2)/2)*exp(log_y_predictions)
all_predictions$`Predictions - Adjusted - Duan` <- predict_from_log_y(.model=model, .newdata=all_predictions)
head(all_predictions)
```

```{r chapter_3_log_log_scaled_regression, fig.height=5, fig.width=plot_width_height_5, message=FALSE, warning=FALSE}
predictions_long <- all_predictions %>% 
    # get the original values, where applicable
    #left_join(metabolic_rate, by = 'Primate Mass') %>%
    pivot_longer(-`Primate Mass`, names_to = 'Prediction Type', values_to='Metabolic Rate')

metabolic_rate_plot <- predictions_long %>%
    ggplot(aes(x=`Primate Mass`, y=`Metabolic Rate`, color=`Prediction Type`)) +
    geom_point(data=metabolic_rate, aes(x=`Primate Mass`, y=`Metabolic Rate`, color=NULL)) +
    geom_text(data=metabolic_rate, 
              aes(x=`Primate Mass`, y=`Metabolic Rate`,
                  label=glue::glue("({ `Primate Mass` }, { `Metabolic Rate` })"),
                  color=NULL),
              vjust=-0.5, check_overlap = TRUE) +
    geom_line()

metabolic_rate_plot +
    scale_x_log10() +
    scale_y_log10() +
    labs(title="Primate Body Mass And Basal Metabolic Rate",
         subtitle = "Log Scaled")
```

```{r chapter_3_log_log_unscaled_regression, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
metabolic_rate_plot +
    labs(title="Primate Body Mass And Basal Metabolic Rate",
         subtitle = "Unscaled")
```

```{r include=FALSE}
rm(model)
rm(all_predictions)
rm(log_y_predictions)
rm(predictions_long)
rm(metabolic_rate_plot)
```

---

### Simulation of Log-Log Predictions

See discussion in previous section regarding systematic underprediction of `y` when dependent varaible is `log y`.

`log y = a + b*log x + random-noise`

```{r chapter_3_log_log_predictions_simulated, fig.height=5, fig.width=plot_width_height_5, message=FALSE, warning=FALSE}
set.seed(1)
intercept <- 4
b_coefficient <- 3
simulated_x <- rexp(100000, rate = 0.5) + 1
noise <- rnorm(100000, sd = 0.5)

simulated_y <- exp(intercept + b_coefficient*log(simulated_x) + noise)

simulated_data <- data.frame(simulated_x, simulated_y)
simulated_data %>%
    ggplot(aes(x=simulated_x, y=simulated_y)) +
    geom_point(alpha=0.1) +
    scale_x_log10(breaks=2^seq(0,6)) +
    scale_y_log10(breaks=10^seq(1,6)) +
    labs(title="Simulated Data (`log y = a + b*log x + random-noise`)",
         subtitle = "Graphed on a log-scale.")
```

---

Create training/test sets, fit model on training data.

```{r}
training_indices <- sample.int(n=nrow(simulated_data), size = 0.7*nrow(simulated_data), replace = FALSE)
training_data <- simulated_data[training_indices,]
test_data <- simulated_data[-training_indices,]
model <- lm(log(simulated_y) ~ log(simulated_x), data=training_data)
summary(model)
```

```{r include=FALSE}
# make sure we don't use training data by accident
rm(training_data)
rm(training_indices)
```

---

Predict on test data.

```{r}
log_y_predictions <- predict(model, newdata=test_data)

# this simple adjustment is also described on pg 206 but assumes normal residuals
test_data$`Predictions - Unadjusted` <- exp(log_y_predictions)
test_data$`Predictions - Adjusted - Simple` <- exp(((summary(model)$sigma)^2)/2)*exp(log_y_predictions)
test_data$`Predictions - Adjusted - Duan` <- predict_from_log_y(.model=model, .newdata=test_data)
head(test_data)
```

---

```{r chapter_3_log_log_scaled_simulation, fig.height=5, fig.width=plot_width_height_5, message=FALSE, warning=FALSE}
predictions_long <- test_data %>%
    select(-simulated_y) %>%
    # get the original values, where applicable
    #left_join(metabolic_rate, by = 'Primate Mass') %>%
    pivot_longer(-simulated_x, names_to = 'Prediction Type', values_to='Predicted Y')

simulated_plot <- predictions_long %>%
    ggplot(aes(x=simulated_x, y=`Predicted Y`, color=`Prediction Type`)) +
    geom_point(data=test_data, aes(x=simulated_x, y=simulated_y, color=NULL), alpha=0.2) +
    geom_line()

simulated_plot +
    scale_x_log10(breaks=2^seq(0,6)) +
    scale_y_log10(breaks=10^seq(1,6)) +
    labs(title="Simulated Data & Predictions",
         subtitle = "Log Scaled",
         caption="The 'Simple' and 'Duan' adjustments are slow close that they overlap,\nand the Duan is being hidden behind the Simple.")
```

---

```{r chapter_3_log_log_unscaled_simulation, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
simulated_plot +
    labs(title="Simulated Data & Predictions",
         subtitle = "Not Scaled",
         caption="The 'Simple' and 'Duan' adjustments are slow close that they overlap,\nand the Duan is being hidden behind the Simple.")
```

---

The adjustments seem to make sense, visualy; but we can check the `Root Mean Square Error` (`RMSE`) to see if the adjustments actually results in a better **out-of-sample** fit, below (which it appears is the case; there is a lower error for the adjusted predictions).

```{r}
rmse = function(fitted, actual){
  sqrt(mean((fitted - actual)^2))
}

rmse(fitted=test_data$`Predictions - Unadjusted`, actual=test_data$simulated_y)
rmse(fitted=test_data$`Predictions - Adjusted - Simple`, actual=test_data$simulated_y)
rmse(fitted=test_data$`Predictions - Adjusted - Duan`, actual=test_data$simulated_y)
```

NOTE: the "Simple" adjustment (found in `Introductory Econometrics, Wooldridge (pg. 206)`) is only valid for residuals that are normally distributed. In this simulation, the residuals are normally distributed; and the Simple and Duan adjustments are quite similar.

---

We can do another performance check using `R-Squared`, which is a measure of the percent of variance in the dependent variable (y) that is explained by the model. The higher the R-squared, the better.

```{r}
#' these functions are from `Business Data Science, Taddy, pg 72`
#' @param y the actual y values
#' @param pred the predictions; must be probabilities (0<pred<1) for binomial
deviance <- function(y, pred, family=c("gaussian","binomial")){
    family <- match.arg(family)
    if(family=="gaussian"){
        return( sum( (y-pred)^2 ) )
    }else{
        if(is.factor(y)) y <- as.numeric(y)>1
        return( -2*sum( y*log(pred) + (1-y)*log(1-pred) ) )
    }
}
#' these functions are from `Business Data Science, Taddy, pg 72`
#' returns r-squared which is a measure of the percent of variance in the dependent variable (y) that is explained by the model.
#' @param y the actual y values
#' @param pred the predictions; must be probabilities (0<pred<1) for binomial
R2 <- function(y, pred, family=c("gaussian","binomial")){
    fam <- match.arg(family)
    if(fam=="binomial"){
        if(is.factor(y)){ y <- as.numeric(y)>1 }
    }
    dev <- deviance(y, pred, family=fam)
    dev0 <- deviance(y, mean(y), family=fam)
    return(1-dev/dev0)
}
```

We can see that the adjusted predictions do have a higher `R-Squared` than the unadjsuted.

```{r}
R2(pred=test_data$`Predictions - Unadjusted`, y=test_data$simulated_y)
R2(pred=test_data$`Predictions - Adjusted - Simple`, y=test_data$simulated_y)
R2(pred=test_data$`Predictions - Adjusted - Duan`, y=test_data$simulated_y)
```

```{r include=FALSE}
rm(intercept)
rm(b_coefficient)
rm(b_coefficient)
rm(simulated_x)
rm(noise)
rm(simulated_y)
rm(simulated_data)
rm(test_data)
rm(model)
rm(log_y_predictions)
rm(predictions_long)
rm(simulated_plot)
```

# Chapter 4 - Statistcal Inference

## Confidence Interval of Proportion

```{r}
sample_size <- 1000
respond_yes <- 700

(estimate <- respond_yes / sample_size)
(standard_error <- sqrt(estimate * (1 - estimate) / sample_size))
(z_scores <- qnorm(c(0.025, 0.975)))
(confidence_interval_95 <- estimate + (z_scores * standard_error))
```

---

Compare to R's `prop.test`.

```{r}
prop.test(x=respond_yes, n=sample_size)
```

```{r include=FALSE}
rm(sample_size)
rm(respond_yes)
rm(estimate)
rm(standard_error)
rm(z_scores)
rm(confidence_interval_95)
```

# Chapter 5 - Simulation

## How many girls in 400 births?

```{r}
probability_girl <- 0.488
sample_size <- 400
# one random sample (simulated)
number_of_simulated_samples <- 1
set.seed(1)
rbinom(n = number_of_simulated_samples, size=sample_size, prob = probability_girl)
```

```{r}
number_of_simulated_samples <- 1000
set.seed(1)
simulations <- rbinom(n = number_of_simulated_samples, size=sample_size, prob = probability_girl)
simulations[1:10]
```

95% Interval

```{r}
quantile(simulations, c(0.025, 0.975))
```

```{r simulations_girls, fig.height=5, fig.width=plot_width_height_5}
hist(simulations)
```

---

Accounting for twins.

First, simulate birth types of 400 births.

```{r}
set.seed(2)
probability_girl_if_twins <- 0.495
probability_of_twins_fraternal <- 1/125  # each has a 49.5% of being a girl
probability_of_twins_identical <- 1/300  # 49.5% chance of being a pair of girls.

simulate_birth_types <- function() {
    
    sample(x=c('fraternal twin', 'identical twin', 'single born'),
           size = sample_size,
           replace = TRUE,
           prob = c(probability_of_twins_fraternal,
                    probability_of_twins_identical,
                    1 - probability_of_twins_fraternal - probability_of_twins_identical))
}
birth_type <- simulate_birth_types()
table(birth_type)
```

Simulating Number of Girls if Fraternal Twin. In this scenario, there are `2` different people, each of which has a ``r format_percent_scale(probability_girl_if_twins)` percent chance of being a girl. So the possible outcomes are `0`, `1`, `2`

- `0`: 0 girls (both boys)
- `1`: 1 girl
- `2`: 2 both

```{r simulations_fraternal_twins, fig.height=5, fig.width=plot_width_height_5}
hist(rbinom(n=10000,  # simulate this scenario 10K times
            size=2, # two different possible chances of being a girl
            prob=probability_girl_if_twins))
```

Simulating Number of Girls if Identical Twin. In this scenario, they are either both boys, or both girls. So the possible outcomes are either `0` or `2`

- `0`: 0 girls (both boys)
- `2`: both girls

In other words, we'll simulate the binary outcome of either both girls or both boys, but the former means we have to count 2 people, so we'll multiple the number of people by 2

```{r simulations_identical_twins, fig.height=5, fig.width=plot_width_height_5}
hist(2 * rbinom(n=10000,  # simulate this scenario 10K times
                size=1, # two different possible chances of being a girl
                prob=probability_girl_if_twins))
```

Now, we will do 1000 simulations of births, considering fraternal/identical twins; each simulation has a sample-size of 400.

```{r}
set.seed(1)
simulation_results <- replicate(1000, {
    birth_type <- simulate_birth_types()
    
    sample_of_girls <- map_dbl(birth_type, ~ {

        if(. == 'fraternal twin') {
            # simulate number of girls for this particular simulated birth_type
            number_of_girls <- rbinom(n=1,
                   size=2, # two different possible chances of being a girl
                   prob=probability_girl_if_twins)
            
        } else if(. == 'identical twin') {
            # simulate number of girls for this particular simulated birth_type
            number_of_girls <- 2 * rbinom(n=1,
                size=1, # two different possible chances of being a girl
                prob=probability_girl_if_twins)
            
        } else if(. == 'single born') {
            # simulate number of girls for this particular simulated birth_type
            number_of_girls <- rbinom(1, 1, probability_girl)
            
        } else {
            stop()
        }
        
        return(number_of_girls)
    })
    stopifnot(length(sample_of_girls) == sample_size)
    return (sum(sample_of_girls))
})
```

```{r}
quantile(simulation_results, c(0.025, 0.975))
```

```{r simulations_twins, fig.height=5, fig.width=plot_width_height_5}
hist(simulation_results)
```

## Simulation of continuous and mixed discrete/continuous models

```{r}
n_sims <- 1000
y1 <- rnorm(n = n_sims, mean = 3, sd = 0.5)
y2 <- exp(x = y1)
y3 <- rbinom(n = n_sims, size = 20, prob = 0.6)
y4 <- rpois(n = n_sims, lambda = 5)
```

```{r simulations_continuous, echo=FALSE, fig.height=6, fig.width=plot_width_height_6}
par(mar=c(4,3,4,3),  mgp=c(1.5,.5,0), tck=-.01)
par(mfrow=c(2,2))
hist(y1, breaks=seq(floor(min(y1)), ceiling(max(y1)), 0.2), main="1000 draws from normal dist with dist. with mean 3, sd 0.5")
hist(y2, breaks=seq(0, ceiling(max(y2)) + 5, 5),  main="1000 draws from corresponding lognormal dist.")
hist(y3, breaks=seq(-0.5, 20.5, 1), main="1000 draws from binomial dist. with 20 tries, probability 0.6")
hist(y4, breaks=seq(-0.5, max(y4) + 1, 1), main="1000 draws from Poisson dist. with mean 5")
```

## Median Absolute Deviation (`MAD SD`)

```{r simulations_mad_sd, fig.height=6, fig.width=plot_width_height_6}
set.seed(1)
z <- rnorm(10000, 5, 2)
hist(z)
```

```{r}
rnd3 <- function(.x) {
    round(.x, 3)
}
glue::glue("mean = { rnd3(mean(z)) }, sd = { rnd3(sd(z)) }, median = { rnd3(median(z)) }, mad sd = { rnd3(mad(z)) }")
```

```{r}
constant <- 1.4826  # 1.483 defined R&OS pg 73; but function uses more specific number
constant * median(abs(z - median(z)))
mad(z)
```

---

The above is a single sample if `10,000` observations.

The `standard error` (i.e. expected **standard deviation** of the **distribution** of **sample means** (if we were going to run this simulation many times (or draw a random sample from the population many times))) is:

```{r}
sd(z) / sqrt(length(z))
```

We can also simulate this.

First, lets run a `1,000` simulations of drawing a sample of `10,000` observations. Each time we'll take the mean of those 10,000 observations. So we'll have a distribution of (1000) sample means.

The standard deviation of the distribution of sample means is:

```{r}
set.seed(1)
simulations <- replicate(1000, mean(rnorm(10000, 5, 2)))
sd(simulations)
```

Which is fairly close to our calculated standard error.

```{r}
quantile(simulations, c(0.025, 0.975))
```

```{r simulations_sample_means, fig.height=6, fig.width=plot_width_height_6}
hist(simulations, main = "Distribution of Sample Means")
```

```{r include=FALSE}
rm(probability_girl)
rm(sample_size)
rm(number_of_simulated_samples)
rm(simulations)
rm(probability_girl_if_twins)
rm(probability_of_twins_fraternal)
rm(probability_of_twins_identical)
rm(simulate_birth_types)
rm(birth_type)
rm(simulation_results)
rm(n_sims)
rm(y1)
rm(y2)
rm(y3)
rm(y4)
rm(z)
rm(constant)
```

# Chapter 9 - Prediction and Bayesian Inference

```{r}
head(hibbs)
```

```{r}
# refresh = 0 supresses the default Stan sampling progress output
model <- stan_glm(vote ~ growth, data=hibbs, refresh=0)
print(model)
```

> These numbers are summaries of a matrix of simulations representing different possible values of the parameters (intercept/slope/residual-standard-deviation). `pg. 113`

> We have a set of `posterior simulations` rather than a single point estimate because we have uncertainty about these parameters. `pg. 113`

```{r}
simulations <- as.matrix(model)
head(simulations)
```

```{r}
model %>% tidy()
```

```{r}
median(simulations[, '(Intercept)'])
mad(simulations[, '(Intercept)'])
```

```{r}
median(simulations[, 'growth'])
mad(simulations[, 'growth'])
```

---

```{r chapter_9_coefficient_joy_plot, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
simulations %>%
    as.data.frame() %>%
    mutate(index=row_number()) %>%
    pivot_longer(-index) %>%
    #mutate(stat.sig = factor(stat.sig, levels=c("TRUE", "FALSE"))) %>%
    #mutate(name = fct_reorder(name, coef_median)) %>%
    ggplot(aes(x=value, y=name)) +
    geom_density_ridges(alpha=0.5) +
    geom_vline(xintercept = 0, color='red')
```

---

```{r chapter_9_coefficient_tiefighter_plot, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
simulations %>%
    as.data.frame() %>%
    mutate(index=row_number()) %>%
    pivot_longer(-index) %>%
    group_by(name) %>%
    summarise(coef_median = median(value),
              coef_mad = mad(value),
              conf.low = coef_median - 2*coef_mad,
              conf.high = coef_median + 2*coef_mad,
              # this is sudo p.value
              # it's the percent of times the simulated values are below zero (if coef_median is greater than zero), or vice-versa
              p.value=ifelse(coef_median > 0, sum(value <= 0) / n(), sum(value >= 0) / n()),
              stat.sig = p.value <= 0.05) %>%
    ungroup() %>%
    mutate(stat.sig = factor(stat.sig, levels=c("TRUE", "FALSE"))) %>%
    mutate(name = fct_reorder(name, coef_median)) %>%
    ggplot(aes(x=coef_median, y=name, color=stat.sig)) +
    geom_point() +
    geom_vline(xintercept = 0, color='red') +
    geom_errorbar(aes(xmin=conf.low, xmax=conf.high)) +
    scale_color_manual(values=c("#37B57F", "#DF585C"))
```

## Point Prediction

```{r}
new_data <- data.frame(growth=2.0)
predict(object = model, newdata = new_data)
```

## Linear Predictor with Uncertainty 

> We can use `posterior_linpred` to get uncertainty in the value of the fitted regression line. (pg. 116)

```{r}
y_linpredict <- posterior_linpred(object=model, newdata = new_data)
head(y_linpredict)
```

> Equivalently we can use the function `posterior_epred`, which returns the expected prediction for a new data point. For linear regression, the expected value is the same as the linear predcitor, but as we dicuss in Chapter 13, these two quantities differ for nonlinear models. (pg 116)

```{r}
head(posterior_epred(object=model, newdata = new_data))
```

To understand what these predictions are, we could have calculated them by hand using the simulations output.

```{r}
simulations %>%
    as.data.frame() %>%
    select(-sigma) %>%
    mutate(prediction = `(Intercept)` + growth * 2.0) %>%
    head()
```

```{r}
simulate_election_results_linpred_conf_int <- function(.growth) {

    predictions <- posterior_linpred(object=model, newdata = data.frame(growth=.growth))
    confidence_intervals <- quantile(predictions, c(0.025, 0.975))
    data.frame(prediction=median(predictions),
               conf.low=unname(confidence_intervals[1]),
               conf.high=unname(confidence_intervals[2]))
}
simulate_election_results_linpred_conf_int(2)
```

```{r chapter_9_posterior_linpred, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
data.frame(growth = -6:6) %>%
    mutate(results = map(growth, ~simulate_election_results_linpred_conf_int(.growth=.))) %>%
    unnest(results) %>%
    ggplot(aes(x=growth, y=prediction)) +
    geom_point() +
    geom_errorbar(aes(ymin=conf.low, ymax=conf.high)) +
    scale_x_continuous(breaks = pretty_breaks(20)) +
    scale_y_continuous(breaks = pretty_breaks(10)) +
    labs(title="Uncertainty in the value of the fitted regression LINE (not the prediction)",
         subtitle="NOTE: I doubt this is how we ever want to express uncertainty in the actual predictions.")
```

NOTE: I doubt this is how we ever want to express uncertainty in the actual predictions.

## Predictive Distribution

> We can construct a vector representing **predictive uncertainty** in a single election. 

Note the confidence intervals are being simulated so the numbers/graph will change each time unless a seed is set.

```{r}
set.seed(1)
y_pred <- posterior_predict(object = model, newdata = new_data)
head(y_pred)
```

If we were to do this by hand, we do the same as before, but add the error term to the computation (which assumes normal distribution).

```{r}
set.seed(1)
simulations %>%
    as.data.frame() %>%
    mutate(error = rnorm(nrow(simulations), 0, sigma)) %>%
    mutate(prediction = `(Intercept)` + growth*2.0 + error) %>%
    head()
```

---

```{r}
simulate_election_results_predict_conf_int <- function(.growth) {

    predictions <- posterior_predict(object=model, newdata = data.frame(growth=.growth))
    confidence_intervals_68 <- quantile(predictions, c(0.16, 1-0.16))
    confidence_intervals_95 <- quantile(predictions, c(0.025, 0.975))
    data.frame(prediction=median(predictions),
               conf.low.68=unname(confidence_intervals_68[1]),
               conf.high.68=unname(confidence_intervals_68[2]),
               conf.low.95=unname(confidence_intervals_95[1]),
               conf.high.95=unname(confidence_intervals_95[2]),
               probability_50_plus = mean(predictions > 50)) %>%
        mutate(stat.sig = !between(50, conf.low.95, conf.high.95))
}
set.seed(1)
simulate_election_results_predict_conf_int(2)
```

```{r}
set.seed(1)
results <- data.frame(growth = -6:6) %>%
    mutate(results = map(growth, ~simulate_election_results_predict_conf_int(.growth=.))) %>%
    unnest(results) 
results
```

Note the confidence intervals are being simulated so the numbers/graph will change each time unless a seed is set.

---

```{r chapter_9_posterior_predict, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
results %>%
    ggplot(aes(x=growth, y=prediction, color=stat.sig)) +
    geom_hline(yintercept = 50, color="#DF585C") +
    geom_point() +
    geom_errorbar(aes(ymin=conf.low.68, ymax=conf.high.68), width=0.5) +
    geom_errorbar(aes(ymin=conf.low.95, ymax=conf.high.95), width=0.5, alpha=0.5) +
    scale_x_continuous(breaks = pretty_breaks(10), labels = function(.x)paste0(.x, "%")) +
    scale_y_continuous(breaks = pretty_breaks(10), labels = function(.x)paste0(.x, "%")) +
    scale_color_manual(values=c("#7A7A7A", "#7AA9CF")) +
    labs(title="Prediction of Incumbent party's vote share, given various economic growth values.",
         x="Economic Growth (% from previous year)",
         y="Prediction of Incumbent party's vote share.")
```

---

```{r chapter_9_posterior_predict_ribbon, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
results %>%
    ggplot(aes(x=growth, y=prediction)) +
    geom_hline(yintercept = 50, color="#DF585C") +
    geom_ribbon(aes(ymin=conf.low.68, ymax=conf.high.68), alpha=0.3) +
    geom_ribbon(aes(ymin=conf.low.95, ymax=conf.high.95), alpha=0.3) +
    geom_point(aes(color=stat.sig)) +
    #geom_point() +
    #geom_errorbar(aes(ymin=conf.low, ymax=conf.high), width=0.5) +
    scale_x_continuous(breaks = pretty_breaks(10), labels = function(.x)paste0(.x, "%")) +
    scale_y_continuous(breaks = pretty_breaks(10), labels = function(.x)paste0(.x, "%")) +
    scale_color_manual(values=c("black", "purple")) +
    labs(title="Prediction of Incumbent party's vote share, given various economic growth values.",
         x="Economic Growth (% from previous year)",
         y="Prediction of Incumbent party's vote share.")
```

---

```{r chapter_9_posterior_predict_prob, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
results %>%
    mutate(growth = factor(growth)) %>%
    ggplot(aes(x=growth, y=probability_50_plus, fill=probability_50_plus)) +
    geom_col() +
    geom_text(aes(label=percent(probability_50_plus, accuracy = 0.1)), vjust=-0.3) +
    scale_y_continuous(breaks=pretty_breaks(10), labels = scales::percent_format()) +
    #scale_fill_gradient2(low = 'red', mid = 'white', high = 'green', midpoint = 0.5) +
    scale_fill_gradient2(low = '#DF585C', mid = 'white', high = '#37B57F', midpoint = 0.5) +
    labs(title="Probability of Incumbent party's vote share > 50%",
         x="Economic Growth (% from previous year)",
         y="Probability of Incumbent party's vote share > 50%")
```

---

If we were to predict on several instances, we would get a column for each input value (i.e. growth of `-2` corresponds to column `1`)

```{r}
head(posterior_predict(object=model, newdata = data.frame(growth=-2:2)))
```

```{r}
all_predictions <- posterior_predict(object=model, newdata = data.frame(growth=-6:6))
head(all_predictions, 20)
```

```{r chapter_9_posterior_predict_points, fig.height=6, fig.width=plot_width_height_6, message=FALSE}
all_predictions <- all_predictions %>%
    as.data.frame() %>%
    mutate(temp=1) %>%
    pivot_longer(-temp, names_to='growth', values_to='prediction') %>%
    mutate(growth = as.numeric(growth) - 6 - 1) %>%
    select(-temp)

results %>%
    ggplot(aes(x=growth, y=prediction, color=stat.sig)) +
    geom_hline(yintercept = 50, color="#DF585C") +
    #geom_point() +
    geom_jitter(data=all_predictions, aes(x=growth, y=prediction, color=NULL), width=0.1, alpha=0.1) +
    #geom_errorbar(aes(ymin=conf.low.68, ymax=conf.high.68), width=0.5) +
    geom_errorbar(aes(ymin=conf.low.95, ymax=conf.high.95), width=0.7) +
    scale_x_continuous(breaks = pretty_breaks(10), labels = function(.x)paste0(.x, "%")) +
    scale_y_continuous(breaks = pretty_breaks(20), labels = function(.x)paste0(.x, "%")) +
    scale_color_manual(values=c("#7A7A7A", "#7AA9CF")) +
    labs(title="Prediction of Incumbent party's vote share, given various economic growth values.",
         x="Economic Growth (% from previous year)",
         y="Prediction of Incumbent party's vote share.")
```

```{r include=FALSE}
rm(model)
rm(simulations)
rm(new_data)
rm(y_linpredict)
rm(simulate_election_results_linpred_conf_int)
rm(simulate_election_results_predict_conf_int)
rm(y_pred)
rm(results)
rm(all_predictions)
```

## 9.3 Prior Information and Bayesian Synthesis

Prior estimate and standard deviation

```{r}
bayesian_updating <- function(.new_vote_count, .new_sample_size) {
 
    prior_estimate <- 0.524
    prior_estimate_sd <- 0.041
    
    (data_estimate <- .new_vote_count / .new_sample_size)
    (data_estimate_sd <- sqrt((.new_vote_count / .new_sample_size) * (1 - (.new_vote_count / .new_sample_size)) / .new_sample_size))
    
    (bayes_estimate <- ((prior_estimate / (prior_estimate_sd^2)) + (data_estimate / (data_estimate_sd^2))) / ((1 / (prior_estimate_sd^2)) + (1 / (data_estimate_sd^2))))
    (bayes_estimate_sd <- 1 / sqrt((1 / (prior_estimate_sd^2)) + (1 / (data_estimate_sd^2))))
    
    print(glue::glue("Prior: { prior_estimate }; Likelihood: { data_estimate }; Posterior: { round(bayes_estimate, 4) }; standard deviation: { round(bayes_estimate_sd, 4) }"))
    
    x <- seq(0, 1, length.out = 1000)
    data.frame(type="Prior Distribution", x=x, value=dnorm(x, prior_estimate, prior_estimate_sd)) %>%
        bind_rows(data.frame(type="Likelihood / Data Distribution", x=x, value=dnorm(x, data_estimate, data_estimate_sd))) %>%
        bind_rows(data.frame(type="Posterior", x=x, value=dnorm(x, bayes_estimate, bayes_estimate_sd))) %>%
        mutate(type = factor(type, levels=c('Prior Distribution', 'Likelihood / Data Distribution', 'Posterior'))) %>%
        ggplot(aes(x=x, y=value, color=type)) +
        geom_line() +
        coord_cartesian(xlim=c(0.4, 0.65)) +
        scale_x_continuous(breaks = pretty_breaks(10), labels = scales::percent_format(accuracy = 1)) +
        theme(axis.title.y=element_blank(),
              axis.text.y=element_blank(),
              axis.ticks.y=element_blank()) +
        labs(title='Bayesian Updating',
             x='% Voting Democrat')   
}
```

```{r chapter_9_bayesian_updating_1, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
bayesian_updating(.new_vote_count = 19, .new_sample_size = 40)
```

```{r chapter_9_bayesian_updating_2, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
bayesian_updating(.new_vote_count = 95, .new_sample_size = 200)
```

```{r chapter_9_bayesian_updating_3, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
bayesian_updating(.new_vote_count = 190, .new_sample_size = 400)
```

```{r include=FALSE}
rm(bayesian_updating)
```

## 9.5 Uniform, weakly informative, and informative priors in regression

### Uniform prior distribution

> We can run `stan_glm` with uniform prior densities for the scale parameter using the `NULL` option. (pg. 123)

```{r}
uniform_model <- stan_glm(vote ~ growth, data=hibbs,
                          refresh = 0,  # refresh = 0 supresses the default Stan sampling progress output
                          prior_intercept = NULL,
                          prior = NULL,
                          prior_aux = NULL)
print(uniform_model)
```

Compare to `lm`; close but not the same.

```{r}
lm_model <- lm(vote ~ growth, data=hibbs)

coef(lm_model)
coef(uniform_model)
```

> These numbers are summaries of a matrix of simulations representing different possible values of the parameters (intercept/slope/residual-standard-deviation). `pg. 113`

> We have a set of `posterior simulations` rather than a single point estimate because we have uncertainty about these parameters. `pg. 113`

```{r}
uniform_coef_simulations <- as.matrix(uniform_model)
head(uniform_coef_simulations)
```

```{r chapter_9_uniform_prior_simulations, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
uniform_coef_simulations %>%
    as.data.frame() %>%
    ggplot(aes(x=`(Intercept)`, y=growth)) +
    geom_point(alpha = 0.5) +
    geom_point(x=coef(uniform_model)['(Intercept)'], y=coef(uniform_model)['growth'], size=2, color='red') +
    scale_x_continuous(breaks = pretty_breaks(10)) +
    scale_y_continuous(breaks = pretty_breaks(10)) +
    labs(title = "Uniform Prior - 4000 posterior draws of the Intercept and growth.",
         subtitle = "(Posterior simulations of the coefficients); Red dot is point of model coefficients")
```

```{r chapter_9_uniform_prior_coefficients, fig.height=5, fig.width=plot_width_height_5, message=FALSE}
uniform_coef_simulations %>%
    as.data.frame() %>%
    mutate(index=row_number()) %>%
    pivot_longer(-index) %>%
    #mutate(stat.sig = factor(stat.sig, levels=c("TRUE", "FALSE"))) %>%
    #mutate(name = fct_reorder(name, coef_median)) %>%
    ggplot(aes(x=value, y=name)) +
    geom_density_ridges(alpha=0.5) +
    geom_vline(xintercept = 0, color='red')
```


```{r}
# Note that if we don't set.seed the predictions will change because they are being simulated
simulate_election_results_predict_conf_int <- function(.model, .growth) {

    predictions <- posterior_predict(object=.model, newdata = data.frame(growth=.growth))
    confidence_intervals_68 <- quantile(predictions, c(0.16, 1-0.16))
    confidence_intervals_95 <- quantile(predictions, c(0.025, 0.975))
    data.frame(prediction=median(predictions),
               conf.low.68=unname(confidence_intervals_68[1]),
               conf.high.68=unname(confidence_intervals_68[2]),
               conf.low.95=unname(confidence_intervals_95[1]),
               conf.high.95=unname(confidence_intervals_95[2]),
               probability_50_plus = mean(predictions > 50)) %>%
        mutate(stat.sig = !between(50, conf.low.95, conf.high.95))
}
set.seed(1)
simulate_election_results_predict_conf_int(.model=uniform_model, .growth=2)
```

```{r}
set.seed(1)
uniform_prediction_summary <- data.frame(growth = -6:6) %>%
    mutate(results = map(growth, ~simulate_election_results_predict_conf_int(.model=uniform_model, .growth=.))) %>%
    unnest(results) 
head(uniform_prediction_summary)
```

```{r chapter_9_uniform_prior_predictions, fig.height=6, fig.width=plot_width_height_6, message=FALSE}
uniform_prediction_summary %>%
    ggplot(aes(x=growth, y=prediction)) +
    geom_hline(yintercept = 50, color="#DF585C") +
    #geom_point() +
    #geom_jitter(data=all_predictions, aes(x=growth, y=prediction, color=NULL), width=0.1, alpha=0.1) +
    #geom_errorbar(aes(ymin=conf.low.68, ymax=conf.high.68), width=0.5) +
    geom_errorbar(aes(ymin=conf.low.95, ymax=conf.high.95), width=0.7) +
    scale_x_continuous(breaks = pretty_breaks(10), labels = function(.x)paste0(.x, "%")) +
    scale_y_continuous(breaks = pretty_breaks(20), labels = function(.x)paste0(.x, "%")) +
    scale_color_manual(values=c("#7A7A7A", "#7AA9CF")) +
    labs(title="Prediction of Incumbent party's vote share, given various economic growth values.",
         subtitle="Using Uniform Prior",
         x="Economic Growth (% from previous year)",
         y="Prediction of Incumbent party's vote share.")
```























```{r include=FALSE}
rm(uniform_model)
rm(lm_model)
rm(uniform_coef_simulations)
rm(uniform_prediction_summary)
```

```{r chapter_9_uniform_prior, fig.height=6, fig.width=plot_width_height_6, message=FALSE}

```











