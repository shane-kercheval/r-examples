---
title: "Regression Examples"
author: "Shane Kercheval"
output:
  md_document:
    variant: markdown_github
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
#devtools::install_github('shane-kercheval/rtools')
#library(rtools)
library(tidyverse)
# library(scales)
# library(stringr)
# library(lubridate)
# library(ggrepel)
# library(forecast)
library(knitr)

options(scipen=999) # non-scientific notation
options(dplyr.summarise.inform=F)

source('../regression/regression_helpers.R')

theme_set(theme_light())

calculate_plot_width <- function(plot_height) { plot_height * 1.61803398875 }
plot_width_height_6 <- calculate_plot_width(6)
plot_width_height_7 <- calculate_plot_width(7)
plot_width_height_8 <- calculate_plot_width(8)
```

# Data

Example shown in Business Data Science pg 134

```{r data}
library(foreign)

descr <- read.dta("data/OHIE_Public_Use_Files/OHIE_Data/oregonhie_descriptive_vars.dta")
prgm <- read.dta("data/OHIE_Public_Use_Files/OHIE_Data/oregonhie_stateprograms_vars.dta")
s12 <- read.dta("data/OHIE_Public_Use_Files/OHIE_Data/oregonhie_survey12m_vars.dta")

#head(descr)
#head(prgm)
#head(s12)

# nicely organized, one row per person
stopifnot(all(s12$person_id == descr$person_id))
stopifnot(all(s12$person_id == prgm$person_id))

P <- descr[,c("person_id","household_id", "numhh_list")]
P <- P %>% rename(numhh = numhh_list)
P$medicaid <- as.numeric(prgm[,"ohp_all_ever_firstn_30sep2009"]=="Enrolled")
P$selected <- as.numeric(descr[,"treatment"]=="Selected")
P$weight <- s12$weight_12m
P$doc_any_12m <- as.numeric(s12$doc_any_12m == "Yes")
levels(P$numhh) <- c("1","2","3+")

P <- P[complete.cases(P),]
head(P)
```

# Average Treatment Effect

ybar is the percent of people with `doc_any_12m == 1` in the `selected == 0` (control) and `selected == 1` (treatment) groups.

ATE is the difference of the percent doc_any_12m in the treatment vs control

```{r}
(ybar <- tapply(P$doc_any_12m, P$selected, mean))
(ATE <- ybar['1'] - ybar['0'])
```

```{r}
(num_sample <- table(P$selected))
(yvar <- tapply(P$doc_any_12m, P$selected, var))
(standard_errors <- sqrt(sum(yvar / num_sample)))
ATE
# 95% confidence interval
ATE + (c(-2, 2) * standard_errors)
```

```{r}
lm(doc_any_12m ~ selected, data=P) %>% tidy()
```

Note: `Intercept` is the average value of `doc_any_12m` when `selected = 0`, which is the same as `ybar['0']` above. `selected` coefficient matches `ATE`.

# Weights

In the example, the data conteight weights because of the imbalance i the data vs the population (e.g. perhaps young people are harder to reach for a survey)

instead of `num_sample` we have `num_selected_weighted`

instead of `ybar` we have `ybar_weighted`

```{r}
(num_selected_weighted <- tapply(P$weight, P$selected, sum))
(num_doc_any_12_weighted <- tapply(P$weight * P$doc_any_12m, P$selected, sum))
(ybar_weighted <- num_doc_any_12_weighted / num_selected_weighted)
(ATE_weighted <- ybar_weighted['1'] - ybar_weighted['0'])
```

```{r}
lm(doc_any_12m ~ selected, weights=weight, data=P) %>% tidy()
```

Now, `Intercept` equals `ybar_weighted['0']`, and `selected` coefficient equals `ATE_weighted`

# Imbalance

A similar scenario, ignoring the population imbalance, is that we have an imballance in the data due to how people are selected, from the control to the treatment: the family members of the people `selected` are also selected. So that families of 2, and 3+ will be overrepresented in the `selected` group. We don't simply want to group by household because we want it at the individual level, and each individual in the household may or may not visit doc in the 12 month period. (Actually the author does do this later on by averaging doc_any_12m per household id)

```{r}
table(P$selected, P$numhh)
table(P$selected, P$numhh) / as.numeric(table(P$selected))
```

Now, we can control for `numhh` by including it in the model.

```{r}
model_simple <- lm(doc_any_12m ~ selected + numhh, data=P)
summary(model_simple)
```

```{r}
get_regression_equation(model_simple, .round_by = 4)
```

```{r}
# the intercept is equivalent to single person household not being selected
# i.e. doc_any_12m = 0.5925(Intercept) + 0.0633*0 + -0.0655*0 + -0.1838*0
predict(model_simple, newdata = data.frame(selected=0, numhh='1'))
coef(model_simple)['(Intercept)']
```

```{r}
predict(model_simple, newdata = data.frame(selected=1, numhh='1'))
coef(model_simple)['(Intercept)'] + coef(model_simple)['selected']
```

Lets generate predictions for every combination, take the differences in predictions for the treatment minus the control, and then take the weighted average of those predictions. That value should equal the value of the `selected` coefficient.

```{r}
new_data <- data.frame(selected=c(1, 1, 1, 0, 0, 0),
                       numhh=c('1', '2', '3+', '1', '2', '3+'))
new_data$predictions <- predict(model_simple, newdata = new_data)
new_data
```

This weighted average of the predictions make sense since the `selected` coefficient is the expected difference across each numhh value (since there is no interaction terms i.e. same slope)

```{r}
# diff the selected == 1 from the selected == 0
# the predictions will have the same diff value
# because (since we aren't interacting the terms) the selected coefficient
# is the expected difference across ALL values of numhh (i.e. same slope, same difference between lines at all values)
# but, we will do the same thing below for the model with interactions
(diffs <- new_data$predictions[1:3] - new_data$predictions[4:6])
# do this across control and treatment
numhh_frequency <- table(P$numhh) / nrow(P)

# weighted average
(ATE <- sum(diffs * numhh_frequency))
coef(model_simple)['selected']
as.numeric(ATE - coef(model_simple)['selected'])
```

`ATE` which is weighted based on the population `numhh` equals `coef(model_simple)['selected']`, i.e. we are controlling for the imbalance in `numhh`.

## Model with Interaction

The author mentions we have to center `numhh`. This is so that the `selected` coefficient is relative to the average value `numhh` and interactions. It makes the `selected` coefficient more interpretable.

`scale=FALSE` means we will only center the data rather than center/scale

```{r}
X <- scale(model.matrix(~numhh, data=P)[, -1], scale=FALSE)
# data centered around 0
colMeans(X)
```

```{r}
model_interaction <- lm(doc_any_12m ~ selected * X, data=P)
summary(model_interaction)
```

```{r}
get_regression_equation(model_interaction, .round_by = 4)
```

The coefficient of `selected` is very close, but different than the model with no interactions.

```{r}
coefficients(model_simple)['selected']
coefficients(model_interaction)['selected']
```

But we didn't center when we did `selected + numhh`.

It turns out the models would have been been identical, with the exception of the Intercept. This is because centering doesn't change the effect of selected or numhh, but now, the coefficient for the Intercept corresponds to the average doc_any_12 value for the average numhh household. (before the Intercept was the average doc_any_12 value for numhh == 1 households). So, in the model without interactions, centering doesn't change selected because selected is the same (i.e. same slope) at every value of numhh.

```{r}
summary(model_simple)
summary(lm(doc_any_12m ~ selected + X, data=P))
```

What if we hadn't centered `numhh` in the interaction?

```{r}
model_interaction_non_centered <- lm(doc_any_12m ~ selected * numhh, data=P)
summary(model_interaction_non_centered)
```

```{r}
coef(model_interaction)['selected']
coef(model_interaction_non_centered)['selected']
```

Before, in the original model with no interaction, the `selected` coefficient was the predicted difference in `selected` vs `not selected` across all `numhh` values (i.e. same slope for each group).

For the model with the interaction, without centering, difference between a `selected` vs `not selected` with the same `numhh` depends on what the `numhh` is. **So the coefficient for `selected` is the average difference between a `selected` vs `not selected` person who both have `numhh1` (1 person in the household), since that is the reference/holdout group.**

For the model with the interaction, with centering, **the coefficient for `selected` is the average difference between a `selected` vs `not selected` person at the average value of `numhh`**

> The implication is that, once you add interaction effects, the main effects may or may not be particularly interesting, at least as they stand, and you should be careful in how you interpret them... Once interaction terms are added, you are primarily interested in their significance, rather than the significance of the terms used to compute them. https://www3.nd.edu/~rwilliam/stats2/l53.pdf

But, if we take this non-centered model, and calculate difference between selected and non-selected using weighted average of frequencies of numhh, then we get the coeffient value of the centered data/model

```{r}
new_data <- data.frame(selected=c(1, 1, 1, 0, 0, 0),
                       numhh=c('1', '2', '3+', '1', '2', '3+'))
```

```{r}
new_data$predictions <- predict(model_interaction_non_centered, newdata = new_data)
```

```{r}
diffs <- new_data$predictions[1:3] - new_data$predictions[4:6]
# do this across control and treatment
numhh_frequency <- table(P$numhh) / nrow(P)
# weighted average
(ATE <- sum(diffs * numhh_frequency))
coef(model_interaction)['selected'] 
```

In summary, if we take the predictions from the non-centered model (with interactions), and weight them according to the `numhh` frequencies, we get the same coefficient that is in the `centered` model (with interactions).


https://www3.nd.edu/~rwilliam/stats2/l53.pdf can explain more on centering & interactions.

It does, 

> * The coefficient for male (3.55) is now the average difference between a male with an average gpa and a female with an average gpa. This is probably more meaningful than looking at the difference between the nonexistent man and woman who are flunking everything.

So translating the `coef(model_interaction)['selected']` ``r coef(model_interaction)['selected']`` is the average difference between selected with average numhh vs not selected with average numhh
